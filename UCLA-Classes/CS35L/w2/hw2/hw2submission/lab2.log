George Owen
405196467

Lab 2 Log
--------------

This is what I did on the lab assignment:


I changed my locale by using the provided command export "LC_ALL=C"

Next, I obtained the required webpage by using:
	curl -O http://web.cs.ucla.edu/classes/winter20/cs35L/assign/assign2.html

then began formatting the words document. 
I used "cp /usr/share/dict/words ~/werds" 
then "sort werds > words" 
to create a sorted list of words in my local directory.


After this, I was ready to start figuring out what the specified commands do:

tr -c 'A-Za-z' '[\n*]' < assign2.html
		this replaces all characters that are not found in the alphabet with newlines.
		Basically, this is an effective way of clearing the formatting of documents

tr -cs 'A-Za-z' '[\n*]' < assign2.html
		this behaves similarly to the previous command,
		(replacing non-alphabetical characters with newlines), 
		but squeezes any repeats so that there's not multiple newlines in a row. 
		This gets rid of excess newlines essentially

tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort
		Once again formats the document to contain only words, 
		but this time sorts the words in alphabetical order as well

tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u
		Sorts in the same manner as the previous command, 
		but only lists unique words (duplicates of the same word are not listed)

tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm - words
		pipes the sorted list from the previous command to a comm command 
		- this compares our formatted document to the master list found in "words." 
		This outputs three columns: words unique to "assign2.html", 
		words unique to "words", and words shared by both, in that order.

tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm -23 words
		makes the same comparison as the last command, 
		but suppresses columns 2 and 3 of comm's output. 
		The only words that will be printed are words not found in the "words" doc 
		(aka incorrectly spelled words)


-------------------------
Next, I began formatting my hawaiian words doc, 
(using the html file obtained from this command:)
curl -o hawaiian.html https://www.mauimapp.com/moolelo/hwnwdshw.htm

Here is my script:

#!/bin/bash


#removes all instances of <u>, </u>, and <br> from the file.
	sed -E "s/\?|<u>|<\/u>|<br>//g" $1 | #hawaiian.html |

#makes sure all english definitions only take up a single line. 
#Basially finds lines that wrap to a newline, appends the next line to the
#current line, and substitures the newline character with a space
#have to run it twice for consistency
	sed -E '/[^>]$/{N; s/\n//}' | 
	sed -E '/[^>]$/{N; s/\n//}' |

#grab only things within <td> tags - these are the actual words
	grep -E '<td.*>.+</td>' |

#delete the first four lines, which are useless html tags
	sed '1,4d' |

#delete every other line, starting at line 2 - this is every english word
	sed '2~2d' |

#removes all td tags from around the words
	sed -E 's/<td[a-zA-Z\ \=\" ]*>|<\/td>//g' |

#switches graves (`) with normal single quotes (')
	tr [\`] [\'] |
#make everything lowercase
	tr [A-Z] [a-z] |
#replaces commas, dashes, and spaces with newlines
	tr -s ,\ \- '[\n*]' |

#delete any empty lines
	sed -E "/./!d" |

#make sure the letters are those in hawaiian
	sed -E "s/[^pk\'mnwlhaeiou]//g" |

#sorts them, and makes sure there are no duplicates
	sort -u


buildwords prints its results to stdout.
I used the buildwords script as follows:

	./buildwords hawaiian.html > hwords

to create a compiled list of words called hwords.
The spellchecker proper is implemented using this command:

	tr 'A-Z' 'a-z' < assign2.html | tr -cs 'A-Za-z' '[\n*]' | 
	sort -u | comm -23 - hwords  #HAWAIIAN SPELLCHECKER

This command takes in an input file (assign2.html) and spellchecks it. 
It accomplishes this by first making all letters lowercase, 
then replaces every nonletter character with a newline. 
After this, it sorts the words alphabetically, 
and compares it to a formattes list of hawaiian words called "hwords". 
This hwords file is the file generated by the buildwords script described above.



Here is my final English spellchecker:

	tr 'A-Z' 'a-z' < assign2.html | tr -cs 'A-Za-z' '[\n*]' |
	sort -u | comm -23 - words

English spellchecker reports 49 misspelled words in assign2.html
Hawaiian spellchecker reports 548 misspelled Hawaiian words in the assign2.html

Words the English spellchecker says are bad, that Hawaiian does not:
	wiki
	lau
There are 2 words English spellchecker catches that Hawaiian does not

Words the Hawaiian spellchecker says are bad, but English does not:
	traditional
	violations
	(most other words)
There are 502 words the Hawaiian Spellchecker catches that English doesn't
